# compas_fairness_data102_lab01
HCE additions to DS 102 course topic of Algorithmic Fairness


# What is Added?

*Lecture*
We added four slides to the DS 102 lecture 05, covering COMPAS as black box, questioning why COMPAS calibrated for gender but not race, and including an extended discussion of accuracy v. fairness 'tradeoff' with suggested class questions.

*Lab*
We added two paragraphs to the introduction of the homework, citing *Wisconsin v. Loomis (2016)* and re-introducing the concept of a black box through that lens.

We added a paragraph on decile scores, explaining how COMPAS generates them, what they mean, and the different 'normative groups' COMPAS divides people into. Following this information, we ask students to consider why COMPAS created the normative groups, and suggest another normative group attribute which could be added.

Finally, we added questions in the "Conclusions and Implications" section, asking students to recapitulate the *Washington v. Loomis* decision and discuss why courts might and might not be interested in using COMPAS.

# Added Learning Objectives

1. Students will consider why certain classification decisions are made.
2. Students will consider how classifications relate to representation, and articulate the stakes of classification decisions.
3. Students will be able to articulate what a decile score is, and consider how this score relates to reality.
4. Students will be able to articulate what COMPAS aims to achieve, and the stakes of any errors.
5. Students will gain a better understanding of how algorithms relate to other real world institutions, such as law courts.
